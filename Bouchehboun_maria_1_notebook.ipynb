{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f5b34029",
      "metadata": {
        "id": "f5b34029"
      },
      "source": [
        "# 1. Local"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4G68088_EC0",
        "outputId": "b6ba9049-6004-4828-9eda-6313b6a8ca10"
      },
      "id": "k4G68088_EC0",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "728d9256",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "728d9256",
        "outputId": "ae72623a-96d6-45c1-fb0b-7c7ee63088ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from Pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from Pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from Pandas) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=3cbaf149b7e2f49d359ab9376d6e77612008de5023656c68f8aaa30e10ae7990\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install Pandas pillow tensorflow pyspark pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a43845",
      "metadata": {
        "id": "33a43845"
      },
      "source": [
        "## 3.4 Import des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a5c0c74f",
      "metadata": {
        "id": "a5c0c74f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras import Model\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "661ff67c",
      "metadata": {
        "id": "661ff67c"
      },
      "source": [
        "## 3.5 Définition des PATH pour charger les images <br /> et enregistrer les résultats\n",
        "\n",
        "Dans cette version locale nous partons du principe que les données <br />\n",
        "sont stockées dans le même répertoire que le notebook.<br />\n",
        "Nous n'utilisons qu'un extrait de **300 images** à traiter dans cette <br />\n",
        "première version en local.<br />\n",
        "L'extrait des images à charger est stockée dans le dossier **Test1**.<br />\n",
        "Nous enregistrerons le résultat de notre traitement <br />\n",
        "dans le dossier \"**Results_Local**\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CVoGY9qKCpf",
        "outputId": "fdf0d013-69cb-4a5a-b419-16ea22eabf83"
      },
      "id": "5CVoGY9qKCpf",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cde0aa67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cde0aa67",
        "outputId": "8261b369-b06b-48d4-8150-a2aa08e63bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: mariabouchehboun\n",
            "Your Kaggle Key: ··········\n",
            "Downloading fruits.zip to ./fruits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.28G/1.28G [00:11<00:00, 117MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/moltean/fruits/data\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_Data = '/content/fruits/fruits-360_dataset/fruits-360/Training/**'\n",
        "PATH_Result = '/content/drive/MyDrive/OC: Data Science/Livrables Soutenance/projet 8/compressed_img'"
      ],
      "metadata": {
        "id": "FMrsGGMNKLO9"
      },
      "id": "FMrsGGMNKLO9",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "da5e637a",
      "metadata": {
        "id": "da5e637a"
      },
      "source": [
        "## 3.6 Création de la SparkSession\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b7bea157",
      "metadata": {
        "id": "b7bea157"
      },
      "outputs": [],
      "source": [
        "spark = (SparkSession\n",
        "             .builder\n",
        "             .appName('P8')\n",
        "             .master('local')\n",
        "             .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n",
        "             .getOrCreate()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c8b53ac",
      "metadata": {
        "id": "5c8b53ac"
      },
      "source": [
        "<u>Nous créons également la variable \"**sc**\" qui est un **SparkContext** issue de la variable **spark**</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "14aeccb1",
      "metadata": {
        "id": "14aeccb1"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a086010",
      "metadata": {
        "id": "5a086010"
      },
      "source": [
        "<u>Affichage des informations de Spark en cours d'execution</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e97bf13b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "e97bf13b",
        "outputId": "1630ede9-6ce4-4379-d6d8-ea21575f8c97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c3e26e250c0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://770c5c93794f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>P8</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "195a88b0",
      "metadata": {
        "id": "195a88b0"
      },
      "source": [
        "## 3.7 Traitement des données\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "386fe0bc",
      "metadata": {
        "id": "386fe0bc"
      },
      "source": [
        "### 3.7.1 Chargement des données\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e68e53b9",
      "metadata": {
        "id": "e68e53b9"
      },
      "outputs": [],
      "source": [
        "images = spark.read.format(\"binaryFile\") \\\n",
        "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
        "  .option(\"recursiveFileLookup\", \"true\") \\\n",
        "  .load(PATH_Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a08b0494",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a08b0494",
        "outputId": "da643d98-4d34-46c6-91d4-5ee192cc45d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- path: string (nullable = true)\n",
            " |-- modificationTime: timestamp (nullable = true)\n",
            " |-- length: long (nullable = true)\n",
            " |-- content: binary (nullable = true)\n",
            " |-- label: string (nullable = true)\n",
            "\n",
            "None\n",
            "+--------------------------------------------------------------------------------------+--------------+\n",
            "|path                                                                                  |label         |\n",
            "+--------------------------------------------------------------------------------------+--------------+\n",
            "|file:/content/fruits/fruits-360_dataset/fruits-360/Training/Raspberry/176_100.jpg     |Raspberry     |\n",
            "|file:/content/fruits/fruits-360_dataset/fruits-360/Training/Raspberry/179_100.jpg     |Raspberry     |\n",
            "|file:/content/fruits/fruits-360_dataset/fruits-360/Training/Pineapple Mini/170_100.jpg|Pineapple Mini|\n",
            "|file:/content/fruits/fruits-360_dataset/fruits-360/Training/Raspberry/157_100.jpg     |Raspberry     |\n",
            "|file:/content/fruits/fruits-360_dataset/fruits-360/Training/Raspberry/131_100.jpg     |Raspberry     |\n",
            "+--------------------------------------------------------------------------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
        "print(images.printSchema())\n",
        "print(images.select('path','label').show(5,False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d47705",
      "metadata": {
        "id": "83d47705"
      },
      "source": [
        "### 3.7.2 Préparation du modèle\n",
        "\n",
        "J"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9cdd9bdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cdd9bdf",
        "outputId": "61fc086f-5057-4c8e-ab7c-1e29d035a2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model = MobileNetV2(weights='imagenet',\n",
        "                    include_top=True,\n",
        "                    input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "99d6b68d",
      "metadata": {
        "id": "99d6b68d"
      },
      "outputs": [],
      "source": [
        "new_model = Model(inputs=model.input,\n",
        "                  outputs=model.layers[-2].output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b197379",
      "metadata": {
        "id": "7b197379"
      },
      "source": [
        "Affichage du résumé de notre nouveau modèle où nous constatons <br />\n",
        "que <u>nous récupérons bien en sortie un vecteur de dimension (1, 1, 1280)</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e8207725",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8207725",
        "outputId": "2b136240-0e51-4455-bc80-9534c172ee61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (None, 112, 112, 32)         864       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalizati  (None, 112, 112, 32)         128       ['Conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)           (None, 112, 112, 32)         0         ['bn_Conv1[0][0]']            \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (D  (None, 112, 112, 32)         288       ['Conv1_relu[0][0]']          \n",
            " epthwiseConv2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN  (None, 112, 112, 32)         128       ['expanded_conv_depthwise[0][0\n",
            "  (BatchNormalization)                                              ]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_re  (None, 112, 112, 32)         0         ['expanded_conv_depthwise_BN[0\n",
            " lu (ReLU)                                                          ][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_project (Con  (None, 112, 112, 16)         512       ['expanded_conv_depthwise_relu\n",
            " v2D)                                                               [0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (  (None, 112, 112, 16)         64        ['expanded_conv_project[0][0]'\n",
            " BatchNormalization)                                                ]                             \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)     (None, 112, 112, 96)         1536      ['expanded_conv_project_BN[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNo  (None, 112, 112, 96)         384       ['block_1_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)  (None, 112, 112, 96)         0         ['block_1_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D  (None, 113, 113, 96)         0         ['block_1_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_1_depthwise (Depthwi  (None, 56, 56, 96)           864       ['block_1_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (Batc  (None, 56, 56, 96)           384       ['block_1_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (Re  (None, 56, 56, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)    (None, 56, 56, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_1_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_1_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_2_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_2_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_depthwise (Depthwi  (None, 56, 56, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (Batc  (None, 56, 56, 144)          576       ['block_2_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (Re  (None, 56, 56, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)    (None, 56, 56, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_2_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_add (Add)           (None, 56, 56, 24)           0         ['block_1_project_BN[0][0]',  \n",
            "                                                                     'block_2_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_2_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_3_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_3_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D  (None, 57, 57, 144)          0         ['block_3_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_3_depthwise (Depthwi  (None, 28, 28, 144)          1296      ['block_3_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (Batc  (None, 28, 28, 144)          576       ['block_3_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (Re  (None, 28, 28, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)    (None, 28, 28, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_3_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_3_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_4_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_4_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_4_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_4_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_add (Add)           (None, 28, 28, 32)           0         ['block_3_project_BN[0][0]',  \n",
            "                                                                     'block_4_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_4_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_5_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_5_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_5_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_5_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_5_add (Add)           (None, 28, 28, 32)           0         ['block_4_add[0][0]',         \n",
            "                                                                     'block_5_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_5_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_6_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_6_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D  (None, 29, 29, 192)          0         ['block_6_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_6_depthwise (Depthwi  (None, 14, 14, 192)          1728      ['block_6_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (Batc  (None, 14, 14, 192)          768       ['block_6_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (Re  (None, 14, 14, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)    (None, 14, 14, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_6_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_6_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_7_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_7_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_7_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_7_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_add (Add)           (None, 14, 14, 64)           0         ['block_6_project_BN[0][0]',  \n",
            "                                                                     'block_7_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_7_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_8_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_8_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_8_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_8_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_8_add (Add)           (None, 14, 14, 64)           0         ['block_7_add[0][0]',         \n",
            "                                                                     'block_8_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_8_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_9_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_9_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_9_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_9_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_9_add (Add)           (None, 14, 14, 64)           0         ['block_8_add[0][0]',         \n",
            "                                                                     'block_9_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)    (None, 14, 14, 384)          24576     ['block_9_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchN  (None, 14, 14, 384)          1536      ['block_10_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU  (None, 14, 14, 384)          0         ['block_10_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_10_depthwise (Depthw  (None, 14, 14, 384)          3456      ['block_10_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (Bat  (None, 14, 14, 384)          1536      ['block_10_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (R  (None, 14, 14, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)   (None, 14, 14, 96)           36864     ['block_10_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_10_project_BN (Batch  (None, 14, 14, 96)           384       ['block_10_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_10_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_11_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_11_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_11_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_11_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_11_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_11_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_11_project_BN (Batch  (None, 14, 14, 96)           384       ['block_11_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_add (Add)          (None, 14, 14, 96)           0         ['block_10_project_BN[0][0]', \n",
            "                                                                     'block_11_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_11_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_12_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_12_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_12_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_12_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_12_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_12_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_12_project_BN (Batch  (None, 14, 14, 96)           384       ['block_12_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_12_add (Add)          (None, 14, 14, 96)           0         ['block_11_add[0][0]',        \n",
            "                                                                     'block_12_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_12_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_13_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_13_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2  (None, 15, 15, 576)          0         ['block_13_expand_relu[0][0]']\n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block_13_depthwise (Depthw  (None, 7, 7, 576)            5184      ['block_13_pad[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (Bat  (None, 7, 7, 576)            2304      ['block_13_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (R  (None, 7, 7, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)   (None, 7, 7, 160)            92160     ['block_13_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_13_project_BN (Batch  (None, 7, 7, 160)            640       ['block_13_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_13_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_14_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_14_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_14_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_14_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_14_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_14_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_14_project_BN (Batch  (None, 7, 7, 160)            640       ['block_14_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_add (Add)          (None, 7, 7, 160)            0         ['block_13_project_BN[0][0]', \n",
            "                                                                     'block_14_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_14_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_15_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_15_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_15_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_15_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_15_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_15_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_15_project_BN (Batch  (None, 7, 7, 160)            640       ['block_15_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_15_add (Add)          (None, 7, 7, 160)            0         ['block_14_add[0][0]',        \n",
            "                                                                     'block_15_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_15_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_16_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_16_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_16_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_16_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_16_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)   (None, 7, 7, 320)            307200    ['block_16_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_16_project_BN (Batch  (None, 7, 7, 320)            1280      ['block_16_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)             (None, 7, 7, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalizat  (None, 7, 7, 1280)           5120      ['Conv_1[0][0]']              \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " out_relu (ReLU)             (None, 7, 7, 1280)           0         ['Conv_1_bn[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 1280)                 0         ['out_relu[0][0]']            \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2257984 (8.61 MB)\n",
            "Trainable params: 2223872 (8.48 MB)\n",
            "Non-trainable params: 34112 (133.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a0adcf5",
      "metadata": {
        "id": "2a0adcf5"
      },
      "source": [
        "Tous les workeurs doivent pouvoir accéder au modèle ainsi qu'à ses poids. <br />\n",
        "Une bonne pratique consiste à charger le modèle sur le driver puis à diffuser <br />\n",
        "ensuite les poids aux différents workeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1cc53ff0",
      "metadata": {
        "id": "1cc53ff0"
      },
      "outputs": [],
      "source": [
        "brodcast_weights = sc.broadcast(new_model.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc0e34e",
      "metadata": {
        "id": "8bc0e34e"
      },
      "source": [
        "<u>Mettons cela sous forme de fonction</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3fd51ba9",
      "metadata": {
        "id": "3fd51ba9"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    \"\"\"\n",
        "    Returns a MobileNetV2 model with top layer removed\n",
        "    and broadcasted pretrained weights.\n",
        "    \"\"\"\n",
        "    model = MobileNetV2(weights='imagenet',\n",
        "                        include_top=True,\n",
        "                        input_shape=(224, 224, 3))\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    new_model = Model(inputs=model.input,\n",
        "                  outputs=model.layers[-2].output)\n",
        "    new_model.set_weights(brodcast_weights.value)\n",
        "    return new_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5620876",
      "metadata": {
        "id": "e5620876"
      },
      "source": [
        "### 3.7.3 Définition du processus de chargement des images et application <br/>de leur featurisation à travers l'utilisation de pandas UDF\n",
        "\n",
        "Ce notebook définit la logique par étapes, jusqu'à Pandas UDF.\n",
        "\n",
        "<u>L'empilement des appels est la suivante</u> :\n",
        "\n",
        "- Pandas UDF\n",
        "  - featuriser une série d'images pd.Series\n",
        "   - prétraiter une image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dc4e5f69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc4e5f69",
        "outputId": "107524be-fcca-4cfd-f7b7-ca5c69cd8216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def preprocess(content):\n",
        "    \"\"\"\n",
        "    Preprocesses raw image bytes for prediction.\n",
        "    \"\"\"\n",
        "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
        "    arr = img_to_array(img)\n",
        "    return preprocess_input(arr)\n",
        "\n",
        "def featurize_series(model, content_series):\n",
        "    \"\"\"\n",
        "    Featurize a pd.Series of raw images using the input model.\n",
        "    :return: a pd.Series of image features\n",
        "    \"\"\"\n",
        "    input = np.stack(content_series.map(preprocess))\n",
        "    preds = model.predict(input)\n",
        "    # For some layers, output features will be multi-dimensional tensors.\n",
        "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
        "    output = [p.flatten() for p in preds]\n",
        "    return pd.Series(output)\n",
        "\n",
        "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
        "def featurize_udf(content_series_iter):\n",
        "    '''\n",
        "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
        "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
        "\n",
        "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
        "                              is a pandas Series of image data.\n",
        "    '''\n",
        "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
        "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
        "    model = model_fn()\n",
        "    for content_series in content_series_iter:\n",
        "        yield featurize_series(model, content_series)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bdf2ef9",
      "metadata": {
        "id": "2bdf2ef9"
      },
      "source": [
        "### 3.7.4 Exécution des actions d'extraction de features\n",
        "\n",
        "Les Pandas UDF, sur de grands enregistrements (par exemple, de très grandes images), <br />\n",
        "peuvent rencontrer des erreurs de type Out Of Memory (OOM).<br />\n",
        "Si vous rencontrez de telles erreurs dans la cellule ci-dessous, <br />\n",
        "essayez de réduire la taille du lot Arrow via 'maxRecordsPerBatch'\n",
        "\n",
        "Je n'utiliserai pas cette commande dans ce projet <br />\n",
        "et je laisse donc la commande en commentaire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1f30d28c",
      "metadata": {
        "id": "1f30d28c"
      },
      "outputs": [],
      "source": [
        "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70f8f95d",
      "metadata": {
        "id": "70f8f95d"
      },
      "source": [
        "Nous pouvons maintenant exécuter la featurisation sur l'ensemble de notre DataFrame Spark.<br />\n",
        "<u>REMARQUE</u> : Cela peut prendre beaucoup de temps, tout dépend du volume de données à traiter. <br />\n",
        "\n",
        "Notre jeu de données de **Test** contient **22819 images**. <br />\n",
        "Cependant, dans l'exécution en mode **local**, <br />\n",
        "nous <u>traiterons un ensemble réduit de **330 images**</u>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "69c1767c",
      "metadata": {
        "id": "69c1767c"
      },
      "outputs": [],
      "source": [
        "features_df = images.repartition(20).select(col(\"path\"),\n",
        "                                            col(\"label\"),\n",
        "                                            featurize_udf(\"content\").alias(\"features\")\n",
        "                                           )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.write.mode(\"overwrite\").parquet(PATH_Result)\n"
      ],
      "metadata": {
        "id": "lleMjcSZL8qJ"
      },
      "id": "lleMjcSZL8qJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_img(img_data):\n",
        "    # Improved resize function\n",
        "    img = Image.open(io.BytesIO(img_data)).resize((224, 224), resample=Image.Resampling.BICUBIC)\n",
        "    # i use simpler image to array conversion\n",
        "    arr = np.array(img)\n",
        "    return arr\n",
        "\n",
        "def pca_img(image_arr):\n",
        "    # this applies for each image\n",
        "    # loading sklearn PCA set to n features\n",
        "    pca = PCA(100)\n",
        "    # apply resize funciton and gather all that in a stack 224*224\n",
        "    resized_imgs = np.stack(image_arr.map(resize_img))\n",
        "    # flatten stack for PCA\n",
        "    imgs_flat = [image.flatten() for image in resized_imgs]\n",
        "    # apply PCA and obtain new array with features\n",
        "    pca_features = pca.fit_transform(imgs_flat)\n",
        "    # remake an image from the PCA reduction\n",
        "    pca_images = pca.inverse_transform(pca_features)\n",
        "    # re-flatten to include as 1d array on tables\n",
        "    pca_imgs_flat = [image.flatten() for image in pca_images]\n",
        "    return pd.Series(pca_imgs_flat)\n",
        "\n",
        "@pandas_udf('array<int>', PandasUDFType.SCALAR_ITER)\n",
        "def pca_udf(img_series):\n",
        "    for image in img_series:\n",
        "        yield pca_img(image)"
      ],
      "metadata": {
        "id": "qm1Cd4LTLuId"
      },
      "id": "qm1Cd4LTLuId",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_df = images.repartition(20).select(col(\"path\"),\n",
        "                                            col(\"label\"),\n",
        "                                            pca_udf(\"content\").alias(\"compressed_img\")\n",
        "                                            )"
      ],
      "metadata": {
        "id": "6tMEq4jcMDrp"
      },
      "id": "6tMEq4jcMDrp",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eb5e83ec",
      "metadata": {
        "id": "eb5e83ec"
      },
      "source": [
        "<u>Rappel du PATH où seront inscrits les fichiers au format \"**parquet**\" <br />\n",
        "contenant nos résultats, à savoir, un DataFrame contenant 3 colonnes</u> :\n",
        " 1. Path des images\n",
        " 2. Label de l'image\n",
        " 3. Vecteur de caractéristiques de l'image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "67fcdb0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67fcdb0f",
        "outputId": "bc89a6d9-9fa0-49b9-c365-ced17a547429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OC: Data Science/Livrables Soutenance/projet 8/compressed_img\n"
          ]
        }
      ],
      "source": [
        "print(PATH_Result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8901db3",
      "metadata": {
        "id": "f8901db3"
      },
      "source": [
        "<u>Enregistrement des données traitées au format \"**parquet**\"</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "95d07466",
      "metadata": {
        "id": "95d07466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "06ba6c24-6ba1-41a4-975f-5570a4dfb025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f7c846e7d2ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresized_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_Result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1721\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m     def text(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "resized_df.write.mode(\"overwrite\").parquet(PATH_Result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9506f21",
      "metadata": {
        "id": "f9506f21"
      },
      "source": [
        "## 3.8 Chargement des données enregistrées et validation du résultat\n",
        "\n",
        "<u>On charge les données fraichement enregistrées dans un **DataFrame Pandas**</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19243bf5",
      "metadata": {
        "id": "19243bf5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27f15070",
      "metadata": {
        "id": "27f15070"
      },
      "source": [
        "<u>On affiche les 5 premières lignes du DataFrame</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a1bcdeb",
      "metadata": {
        "id": "8a1bcdeb"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2794fca",
      "metadata": {
        "id": "e2794fca"
      },
      "source": [
        "<u>On valide que la dimension du vecteur de caractéristiques des images est bien de dimension 1280</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb933b9",
      "metadata": {
        "id": "0bb933b9"
      },
      "outputs": [],
      "source": [
        "df.loc[0,'features'].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/OC: Data Science/Livrables Soutenance/projet 8/fichier.csv')"
      ],
      "metadata": {
        "id": "xbcjiFRQNFAk"
      },
      "id": "xbcjiFRQNFAk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Cloud"
      ],
      "metadata": {
        "id": "l2S9mJ5c_Nww"
      },
      "id": "l2S9mJ5c_Nww"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras import Model\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split"
      ],
      "metadata": {
        "id": "481Jiwga_Mr0"
      },
      "id": "481Jiwga_Mr0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = 's3://fruit-project'\n",
        "PATH_Data = PATH+'/Test'\n",
        "PATH_Result = PATH\n",
        "print('PATH:        '+\\\n",
        "      PATH+'\\nPATH_Data:   '+\\\n",
        "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
      ],
      "metadata": {
        "id": "DlpXityiAjyc"
      },
      "id": "DlpXityiAjyc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = spark.read.format(\"binaryFile\") \\\n",
        "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
        "  .option(\"recursiveFileLookup\", \"true\") \\\n",
        "  .load(PATH_Data)"
      ],
      "metadata": {
        "id": "uUAAOMXYAj2Q"
      },
      "id": "uUAAOMXYAj2Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.show(5)"
      ],
      "metadata": {
        "id": "iCL4Ir_7Aj9Y"
      },
      "id": "iCL4Ir_7Aj9Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
        "print(images.printSchema())\n",
        "print(images.select('path','label').show(5,False))"
      ],
      "metadata": {
        "id": "lzHngNWvAj_X"
      },
      "id": "lzHngNWvAj_X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MobileNetV2(weights='imagenet',\n",
        "                    include_top=True,\n",
        "                    input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "kb5dXxxwAkBF"
      },
      "id": "kb5dXxxwAkBF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = Model(inputs=model.input,\n",
        "                  outputs=model.layers[-2].output)"
      ],
      "metadata": {
        "id": "-8oN-7piAkC8"
      },
      "id": "-8oN-7piAkC8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brodcast_weights = sc.broadcast(new_model.get_weights())"
      ],
      "metadata": {
        "id": "giWO7mTQAkE2"
      },
      "id": "giWO7mTQAkE2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.summary()"
      ],
      "metadata": {
        "id": "CVRNKz17A0N5"
      },
      "id": "CVRNKz17A0N5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_fn():\n",
        "    \"\"\"\n",
        "    Returns a MobileNetV2 model with top layer removed\n",
        "    and broadcasted pretrained weights.\n",
        "    \"\"\"\n",
        "    model = MobileNetV2(weights='imagenet',\n",
        "                        include_top=True,\n",
        "                        input_shape=(224, 224, 3))\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    new_model = Model(inputs=model.input,\n",
        "                  outputs=model.layers[-2].output)\n",
        "    new_model.set_weights(brodcast_weights.value)\n",
        "    return new_model"
      ],
      "metadata": {
        "id": "v53IJlZuA0Q2"
      },
      "id": "v53IJlZuA0Q2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(content):\n",
        "    \"\"\"\n",
        "    Preprocesses raw image bytes for prediction.\n",
        "    \"\"\"\n",
        "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
        "    arr = img_to_array(img)\n",
        "    return preprocess_input(arr)\n",
        "\n",
        "def featurize_series(model, content_series):\n",
        "    \"\"\"\n",
        "    Featurize a pd.Series of raw images using the input model.\n",
        "    :return: a pd.Series of image features\n",
        "    \"\"\"\n",
        "    input = np.stack(content_series.map(preprocess))\n",
        "    preds = model.predict(input)\n",
        "    # For some layers, output features will be multi-dimensional tensors.\n",
        "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
        "    output = [p.flatten() for p in preds]\n",
        "    return pd.Series(output)\n",
        "\n",
        "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
        "def featurize_udf(content_series_iter):\n",
        "    '''\n",
        "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
        "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
        "\n",
        "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
        "                              is a pandas Series of image data.\n",
        "    '''\n",
        "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
        "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
        "    model = model_fn()\n",
        "    for content_series in content_series_iter:\n",
        "        yield featurize_series(model, content_series)"
      ],
      "metadata": {
        "id": "23f5TXPpA0S9"
      },
      "id": "23f5TXPpA0S9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
      ],
      "metadata": {
        "id": "qvW60TddA0U3"
      },
      "id": "qvW60TddA0U3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df = images.repartition(24).select(col(\"path\"),\n",
        "                                            col(\"label\"),\n",
        "                                            featurize_udf(\"content\").alias(\"features\")\n",
        "                                           )"
      ],
      "metadata": {
        "id": "c-vsWGpNBZPn"
      },
      "id": "c-vsWGpNBZPn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_img(img_data):\n",
        "    # Improved resize function\n",
        "    img = Image.open(io.BytesIO(img_data)).resize((224, 224), resample=Image.Resampling.BICUBIC)\n",
        "    # i use simpler image to array conversion\n",
        "    arr = np.array(img)\n",
        "    return arr\n",
        "\n",
        "def pca_img(image_arr):\n",
        "    # this applies for each image\n",
        "    # loading sklearn PCA set to n features\n",
        "    pca = PCA(100)\n",
        "    # apply resize funciton and gather all that in a stack 224*224\n",
        "    resized_imgs = np.stack(image_arr.map(resize_img))\n",
        "    # flatten stack for PCA\n",
        "    imgs_flat = [image.flatten() for image in resized_imgs]\n",
        "    # apply PCA and obtain new array with features\n",
        "    pca_features = pca.fit_transform(imgs_flat)\n",
        "    # remake an image from the PCA reduction\n",
        "    pca_images = pca.inverse_transform(pca_features)\n",
        "    # re-flatten to include as 1d array on tables\n",
        "    pca_imgs_flat = [image.flatten() for image in pca_images]\n",
        "    return pd.Series(pca_imgs_flat)\n",
        "\n",
        "@pandas_udf('array<int>', PandasUDFType.SCALAR_ITER)\n",
        "def pca_udf(img_series):\n",
        "    for image in img_series:\n",
        "        yield pca_img(image)"
      ],
      "metadata": {
        "id": "BXN3_7uwBZS5"
      },
      "id": "BXN3_7uwBZS5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_df = images.repartition(20).select(col(\"path\"),\n",
        "                                            col(\"label\"),\n",
        "                                            pca_udf(\"content\").alias(\"compressed_img\")\n",
        "                                            )"
      ],
      "metadata": {
        "id": "-R_StaeUBZZp"
      },
      "id": "-R_StaeUBZZp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(PATH_Result)"
      ],
      "metadata": {
        "id": "WZoVaw9qBkTi"
      },
      "id": "WZoVaw9qBkTi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.write.mode(\"overwrite\").parquet(PATH_Result)"
      ],
      "metadata": {
        "id": "b6FiquLBBll7"
      },
      "id": "b6FiquLBBll7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
      ],
      "metadata": {
        "id": "LHjydkciBoTU"
      },
      "id": "LHjydkciBoTU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ZYrvrTEeBoYc"
      },
      "id": "ZYrvrTEeBoYc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[0,'features'].shape"
      ],
      "metadata": {
        "id": "FfdRC6xMBohP"
      },
      "id": "FfdRC6xMBohP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "7_S4sC9ZBoly"
      },
      "id": "7_S4sC9ZBoly",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#on arrete la session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "kVVcmKF7CT2x"
      },
      "id": "kVVcmKF7CT2x",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "432.4px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}